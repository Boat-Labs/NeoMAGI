# 0028-compaction-summary-model-strategy-for-m2

- Status: accepted
- Date: 2026-02-21

## 选了什么
- M2 的 compaction 摘要生成默认使用当前会话同一模型（same model），不新增独立 `compaction_model` 配置项。
- 摘要输出采用固定结构，至少包含：`facts`、`decisions`、`open_todos`、`user_prefs`、`timeline`。
- 生成参数采用低温度（建议 `0~0.2`）并设置明确的输出 token 上限。
- 失败兜底：当摘要生成失败时，退化为“保留最近 N turn + 标记 compaction 未完成”，禁止静默丢弃历史。

## 为什么
- compaction 位于长期会话连续性的关键路径，摘要质量会直接影响后续多轮任务成功率。
- same model 方案概念最少，不引入额外模型路由、配置面和兼容性分支，符合“最小可用闭环”和“对抗熵增”原则。
- 当前 compaction 触发频率低，单次约 1-2k input tokens 的额外开销在 M2 阶段可控。
- 先确保语义保真与稳定性，再在后续版本做成本优化，风险更低。

## 放弃了什么
- 方案 A：可配置独立低成本模型（如 `gpt-4o-mini`）作为 compaction 模型。
  - 放弃原因：引入配置复杂度与兼容性测试面，且摘要质量波动在 M2 阶段不可接受。
  - 处理方式：保留为 M2.x 演进项，待有观测数据后再评估。
- 方案 B：纯规则裁剪（不使用 LLM，仅保留最近 N turn）。
  - 放弃原因：缺乏语义压缩能力，历史信息召回显著下降，长期连续性退化明显。
  - 处理方式：仅作为模型调用异常时的灾备兜底，不作为主路径。

## 影响
- M2 实现保持最小复杂度，优先交付可用且稳定的长对话压缩闭环。
- 短期不引入额外模型配置项，减少使用与运维心智负担。
- 必须补充 compaction 观测指标：触发次数、输入/输出 token、失败率、耗时。
- 为后续是否引入 cheaper model 提供可量化决策依据。
