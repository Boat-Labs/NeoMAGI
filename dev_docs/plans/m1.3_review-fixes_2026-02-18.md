# M1.3 评审修复计划

## Context

基于 M1.3 完成后的用户评审，共 6 项发现（3×P1 + 2×P2 + 1×P3）。

| 编号 | 级别 | 发现 | 状态 |
|------|------|------|------|
| R1 | P1 | 会话持久化：多 worker seq + 同步 persist + 租约锁串行化 + 内存一致性 | **待修复** |
| R2 | P1 | 数据库运行模式改为硬依赖（删除 memory fallback） | **待修复** |
| R3 | P1 | chat.history 决议注释引用 | ✅ 已完成 |
| R4 | P2 | ModelClient 空 choices 防护 + 回归测试 | ✅ 已有实现和测试 |
| R5 | P2 | 前端 history 去重策略（全量替换 + 重连守卫 + 失败恢复 + 输入保护） | **待修复** |
| R6 | P3 | 补充协议边界 + 并发持久化 + 串行化 + 守卫恢复测试 | **待补齐** |

本次修复范围：R1 + R2 + R5 + R6。
R3/R4 已到位，无代码改动。

关联决议：
- [Decision 0019] chat.history display semantics boundary
- [Decision 0020] Database hard dependency with fail-fast startup
- [Decision 0021] Multi-worker session ordering and no-silent-drop
- [Decision 0022] M1.3 soft session serialization (token + TTL lease lock boundary)

---

## R1: 会话持久化全面修复（P1）

R1 涉及六个紧密关联的问题，统一在此解决。

### 问题清单

**问题 1 — 多 worker seq 冲突**: 多 worker 部署下，每个 worker 有独立内存
session 缓存。`seq = len(session.messages) - 1` 基于本地内存分配，跨 worker
会产生重复 seq。

**问题 2 — select-then-insert 竞态**: `_persist_message` 对 SessionRecord 做
select-then-insert，并发 task 可能重复 insert → IntegrityError。

**问题 3 — fire-and-forget 违反 Decision 0021**: `_persist_message` 以
`asyncio.create_task` fire-and-forget 调用，DB 失败仅打日志。[Decision 0021]
要求"最终写入成功或向调用方显式失败"。

**问题 4 — 多 worker 上下文错序**: 即使 DB seq 正确，两个 worker 并发处理同一
session_id 时，各自从本地内存构建 prompt，互相看不到对方的消息，LLM 推理基于
不完整上下文。DB 写入顺序正确不等于处理顺序正确。

**问题 5 — 失败后内存残留**: `append_message` 先写内存再 persist，persist
失败时消息已留在 `session.messages`，后续请求会将"幽灵消息"带入 LLM 上下文，
内存与 DB 状态不一致。

**问题 6 — 跨 worker 切换时上下文丢失**: 请求 1 落到 Worker A 并持久化消息。
重连后请求 2 落到 Worker B（非并发，纯顺序切换）。当前 `load_session_from_db`
有 `if session_id in self._sessions: return True` 短路——Worker B 用本地空缓存
或旧缓存构建 prompt，历史上下文丢失。此问题不需要并发即可触发。

### 设计目标

1. seq 分配在 DB 级原子完成，保证跨 worker 唯一性和顺序性。
2. 持久化失败向调用方显式传播，不允许 silent drop。
3. 同一 session_id 的请求处理在跨 worker 下串行化，防止上下文错序。
4. 持久化成功后才写内存，失败时内存状态不变。
5. 跨 worker 切换时，强制从 DB 刷新本地 session 缓存，保证上下文连续性。

### 方案

**A. Session counter 行锁**（解决问题 1/2）:
在 `SessionRecord` 上维护 `next_seq` 计数器，通过
INSERT ... ON CONFLICT DO UPDATE ... RETURNING 原子分配 seq。

**B. 同步 persist + 先 DB 后内存**（解决问题 3/5）:
`append_message` 改为 async，先 await `_persist_message`，成功后再写内存。
失败时内存不变，异常传播到调用方。

**C. 带 owner token 的租约锁 + SESSION_BUSY 错误**（解决问题 4）:
在 `SessionRecord` 加 `lock_token` + `processing_since` 列。`chat.send` 入口
处 try-claim session，claim 成功返回 `lock_token`（UUID）。claim 失败 → 立即
返回 `SESSION_BUSY` RPC error。

release 时 `WHERE session_id AND lock_token`——只有持有者能释放自己的锁。
防止 Worker A 超时后被 B 接管时，A 完成后误释放 B 的锁导致 C 穿透。

TTL 可配置（默认 300s），通过 `GATEWAY_SESSION_CLAIM_TTL_SECONDS` 环境变量设置。
测试中降至 2s 避免等待。

**D. claim 后强制刷新 session 缓存**（解决问题 6）:
`load_session_from_db` 增加 `force` 参数。`_handle_chat_send` 在 claim 成功后、
进入 `handle_message` 前，调用 `load_session_from_db(session_id, force=True)`
无条件从 DB 重建本地缓存。保证即使 Worker B 有空缓存或旧缓存，prompt 构建前
本地状态与 DB 一致。claim 管锁，reload 管数据，职责分离。

**已知限制（不在本次解决）**: lock_token 防止误释放，但不阻止超时后并发处理——
Worker A 超时后 B 拿到锁，A 仍在继续（不知锁被偷）。此场景下 DB seq 仍正确
（counter 原子），但 LLM 可能看到不完整上下文（quality degradation，非 data
corruption）。彻底解决需 fencing（每次 persist 验 lock_token）或 heartbeat
续租。默认 300s TTL 使此场景极少触发。

### 改动

**1. `src/session/models.py` — SessionRecord 加 `next_seq` + `lock_token` + `processing_since`；MessageRecord 加 UNIQUE 约束**

```python
from sqlalchemy import UniqueConstraint

class SessionRecord(Base):
    __tablename__ = "sessions"
    __table_args__ = {"schema": DB_SCHEMA}

    id: Mapped[str] = mapped_column(String(128), primary_key=True)
    next_seq: Mapped[int] = mapped_column(Integer, default=0)
    lock_token: Mapped[str | None] = mapped_column(String(36), nullable=True, default=None)
    processing_since: Mapped[datetime | None] = mapped_column(
        DateTime(timezone=True), nullable=True, default=None
    )
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()
    )
    messages: Mapped[list[MessageRecord]] = relationship(
        back_populates="session", order_by="MessageRecord.seq", cascade="all, delete-orphan"
    )

class MessageRecord(Base):
    __tablename__ = "messages"
    __table_args__ = (
        UniqueConstraint("session_id", "seq", name="uq_messages_session_seq"),
        {"schema": DB_SCHEMA},
    )
    # ... 其余不变
```

**2. `src/config/settings.py` — 新增 `session_claim_ttl_seconds`**

```python
# 沿用现有 settings.py 架构：每个子配置是独立 BaseSettings + env_prefix。
class GatewaySettings(BaseSettings):
    """Gateway server settings. Env vars prefixed with GATEWAY_."""

    model_config = SettingsConfigDict(env_prefix="GATEWAY_")

    host: str = "0.0.0.0"
    port: int = 19789
    session_claim_ttl_seconds: int = Field(
        300, gt=0, le=3600,
        validation_alias="GATEWAY_SESSION_CLAIM_TTL_SECONDS",
    )

class Settings(BaseSettings):
    # ...
    gateway: GatewaySettings = Field(default_factory=GatewaySettings)
    # ...
```

环境变量名：`GATEWAY_SESSION_CLAIM_TTL_SECONDS`（带前缀，与现有 `DATABASE_SCHEMA`、
`DATABASE_ALLOW_MEMORY_FALLBACK` 的 validation_alias 模式一致）。

**3. `src/session/manager.py` — `try_claim_session` / `release_session`（带 lock_token）**

```python
async def try_claim_session(self, session_id: str, ttl_seconds: int = 300) -> str | None:
    """Try to claim a session for exclusive processing.

    [Decision 0021] Session-level serialization: prevents concurrent
    multi-worker processing of the same session.

    Uses lock_token (UUID) as owner identifier. Only the holder can release.
    TTL auto-releases stale claims (crashed worker recovery).

    Returns lock_token (str) if claimed, None if session is busy.
    """
    import uuid
    from sqlalchemy.dialects.postgresql import insert as pg_insert

    lock_token = str(uuid.uuid4())

    async with self._db() as db_session:
        stmt = (
            pg_insert(SessionRecord)
            .values(
                id=session_id,
                lock_token=lock_token,
                processing_since=func.now(),
                next_seq=0,
            )
            .on_conflict_do_update(
                index_elements=["id"],
                set_={
                    "lock_token": lock_token,
                    "processing_since": func.now(),
                },
                where=or_(
                    SessionRecord.processing_since.is_(None),
                    SessionRecord.processing_since
                    < func.now() - text(f"interval '{ttl_seconds} seconds'"),
                ),
            )
            .returning(SessionRecord.id)
        )
        result = await db_session.execute(stmt)
        claimed = result.scalar_one_or_none() is not None
        await db_session.commit()
        return lock_token if claimed else None

async def release_session(self, session_id: str, lock_token: str) -> None:
    """Release session processing claim. Only succeeds if lock_token matches.

    If another worker has already taken over (token mismatch after TTL
    expiry), this is a no-op — prevents cascading release where Worker A
    clears Worker B's lock.
    """
    async with self._db() as db_session:
        await db_session.execute(
            update(SessionRecord)
            .where(
                SessionRecord.id == session_id,
                SessionRecord.lock_token == lock_token,
            )
            .values(processing_since=None, lock_token=None)
        )
        await db_session.commit()
```

关键语义：
- 新 session：INSERT 成功，同时创建 session + claim + lock_token。
- session 空闲（`processing_since IS NULL`）：UPDATE 成功，写入新 lock_token。
- session 忙（`processing_since` 在 TTL 内）：UPDATE WHERE false → RETURNING 空 → 返回 None。
- session 超时（`processing_since` 超过 TTL）：UPDATE 成功，新 worker 接管。
- release token 不匹配：`WHERE lock_token = :token` 不满足 → 0 rows affected → no-op。
- PostgreSQL 行锁保证并发 claim 原子串行。
- 不持有 DB 连接等待 LLM——claim/release 各一次短事务。

**4. `src/session/manager.py` — `load_session_from_db` 增加 `force` 参数**

```python
async def load_session_from_db(self, session_id: str, *, force: bool = False) -> bool:
    """Load a session from DB into memory cache. Returns True if found.

    When force=True, unconditionally reload from DB even if session exists
    in local cache. Required for cross-worker handoff to ensure prompt is
    built from latest DB state, not stale local cache.

    [Decision 0021] force=True changes exception semantics: DB errors
    propagate instead of returning False. Prevents silent degradation to
    empty/stale context. "Session not found" (record is None) still
    returns False — a new session with no history is legitimate.
    """
    if session_id in self._sessions and not force:
        return True

    try:
        async with self._db() as db_session:
            # ... 原有查询逻辑 ...
            record = ...  # select SessionRecord
            if record is None:
                return False  # 合法：session 尚不存在于 DB（首次请求）

            # ... 加载 messages，覆盖 self._sessions[session_id] ...
            return True
    except Exception:
        if force:
            raise  # [Decision 0021] force reload failure must not silently degrade
        logger.exception("session_load_failed", session_id=session_id)
        return False
```

`force=False` 保持现有调用方语义不变（`get_history_for_display` 等）。
`force=True` 仅在 `_handle_chat_send` 的 claim-after-reload 路径使用。
异常传播路径：`load_session_from_db` raise → `_handle_chat_send` try 块 → 外层 `_handle_rpc_message` except → INTERNAL_ERROR → finally release。

**5. `src/session/manager.py` — `append_message` 改为 async + 先 DB 后内存**（原编号 4）

```python
async def append_message(
    self,
    session_id: str,
    role: str,
    content: str,
    *,
    tool_calls: list[dict[str, Any]] | None = None,
    tool_call_id: str | None = None,
) -> Message:
    """Append a message to a session: persist to DB first, then write memory.

    [Decision 0021] Persist is synchronous — failure propagates to caller,
    no silent drop. Memory is only updated after DB confirms success,
    preventing ghost messages in local cache on failure.
    """
    session = self.get_or_create(session_id)
    msg = Message(
        role=role,
        content=content,
        tool_calls=tool_calls,
        tool_call_id=tool_call_id,
    )

    # [Decision 0021] Persist first — no memory pollution on failure
    await self._persist_message(session_id, msg)

    # Only reach here if persist succeeded
    session.messages.append(msg)
    session.updated_at = msg.timestamp
    logger.debug("message_appended", role=role, session_id=session_id)
    return msg
```

**6. `src/session/manager.py` — `_persist_message` DB 级 seq 分配**（原编号 5）

```python
async def _persist_message(self, session_id: str, msg: Message) -> None:
    """Persist a single message to DB with atomic seq allocation.

    [Decision 0021] Raises on failure — no silent drop.
    SQLAlchemy async context manager auto-rollbacks on exception.
    """
    from sqlalchemy.dialects.postgresql import insert as pg_insert

    async with self._db() as db_session:
        # Atomic: upsert session + allocate seq (row lock serializes per-session)
        stmt = (
            pg_insert(SessionRecord)
            .values(id=session_id, next_seq=1)
            .on_conflict_do_update(
                index_elements=["id"],
                set_={"next_seq": SessionRecord.next_seq + 1},
            )
            .returning(
                # 新 session: next_seq 从 0→1, 返回 1-1=0
                # 已有 session: next_seq 从 N→N+1, 返回 N+1-1=N
                SessionRecord.next_seq - 1
            )
        )
        result = await db_session.execute(stmt)
        seq = result.scalar_one()

        db_session.add(
            MessageRecord(
                session_id=session_id,
                seq=seq,
                role=msg.role,
                content=msg.content,
                tool_calls=msg.tool_calls,
                tool_call_id=msg.tool_call_id,
            )
        )
        await db_session.commit()
```

异常处理不在 `_persist_message` 内部，`async with` 自动 rollback 后传播。
无手动 try/except/rollback，避免二次异常风险。

注意：`_persist_message` 的 upsert 只更新 `next_seq`，不影响 `lock_token`/`processing_since`。
`try_claim_session` 的 upsert 只更新 `lock_token`/`processing_since`，不影响 `next_seq`。
两个 upsert 操作的 `set_` 子句互不干扰。

**7. `src/agent/agent.py` — 4 处调用改为 await**（原编号 6）

```python
# L65:  用户消息
await self._session_manager.append_message(session_id, "user", content)

# L102: assistant + tool_calls
await self._session_manager.append_message(
    session_id, "assistant", response.content or "", tool_calls=tool_calls_data,
)

# L130: tool result
await self._session_manager.append_message(
    session_id, "tool", json.dumps(result), tool_call_id=tc.id,
)

# L149: final assistant text
await self._session_manager.append_message(session_id, "assistant", text)
```

改动纯机械：加 `await`，无逻辑变化。`handle_message` 本身已是 async generator。

**8. `src/gateway/app.py` — `_handle_chat_send` 包装 claim + force reload + release（带 lock_token）**（原编号 7）

```python
async def _handle_chat_send(
    websocket: WebSocket, request_id: str, params: dict
) -> None:
    """Handle chat.send: claim session, invoke agent loop, stream events, release."""
    parsed = ChatSendParams.model_validate(params)
    session_manager: SessionManager = websocket.app.state.session_manager
    settings = get_settings()

    # [Decision 0021] Session-level serialization: try-claim before processing
    lock_token = await session_manager.try_claim_session(
        parsed.session_id,
        ttl_seconds=settings.gateway.session_claim_ttl_seconds,
    )
    if lock_token is None:
        error = RPCError(
            id=request_id,
            error=RPCErrorData(
                code="SESSION_BUSY",
                message="Session is being processed by another request. Please try again.",
            ),
        )
        await websocket.send_text(error.model_dump_json())
        return

    try:
        # [Decision 0021] Force-reload session from DB before building prompt.
        # Ensures cross-worker handoff has complete history, not stale local cache.
        await session_manager.load_session_from_db(parsed.session_id, force=True)

        agent_loop: AgentLoop = websocket.app.state.agent_loop
        async for event in agent_loop.handle_message(
            session_id=parsed.session_id,
            content=parsed.content,
        ):
            if isinstance(event, TextChunk):
                chunk = RPCStreamChunk(
                    id=request_id,
                    data=StreamChunkData(content=event.content, done=False),
                )
                await websocket.send_text(chunk.model_dump_json())
            elif isinstance(event, ToolCallInfo):
                tool_msg = RPCToolCall(
                    id=request_id,
                    data=ToolCallData(
                        tool_name=event.tool_name,
                        arguments=event.arguments,
                        call_id=event.call_id,
                    ),
                )
                await websocket.send_text(tool_msg.model_dump_json())

        done_chunk = RPCStreamChunk(
            id=request_id,
            data=StreamChunkData(content="", done=True),
        )
        await websocket.send_text(done_chunk.model_dump_json())
    finally:
        try:
            await session_manager.release_session(parsed.session_id, lock_token)
        except Exception:
            # [Decision 0022] release is best-effort; TTL recovers stale locks.
            # Do NOT re-raise — avoid sending INTERNAL_ERROR after done=true.
            logger.exception(
                "session_release_failed",
                session_id=parsed.session_id,
                msg="Lock will be recovered by TTL expiry",
            )
```

异常传播路径：`_persist_message` → `append_message` → `handle_message`
→ `_handle_chat_send` try 块 → 外层 except（已有 → RPC error）→ finally release（best-effort）。
release 失败只记日志，不向客户端二次报错——防止"done=true 后又收到 error"的状态污染。
锁释放失败依赖 TTL 回收（[Decision 0022] 租约锁设计的一部分）。

**9. `src/gateway/protocol.py` — 新增 SESSION_BUSY 错误码**（原编号 8）

`SESSION_BUSY` 加入已有的 error code 体系（与 `INTERNAL_ERROR`、`LLM_ERROR` 并列）。

**10. 数据库迁移**（原编号 9）

新增 migration 文件：
- `sessions` 表添加 `next_seq INTEGER NOT NULL DEFAULT 0` 列
- `sessions` 表添加 `lock_token VARCHAR(36) NULL` 列
- `sessions` 表添加 `processing_since TIMESTAMPTZ NULL` 列
- `messages` 表添加 `uq_messages_session_seq` UNIQUE 约束
- 回填 `next_seq`:
  `UPDATE sessions SET next_seq = (SELECT COALESCE(MAX(seq), -1) + 1 FROM messages WHERE messages.session_id = sessions.id)`

---

## R2: 数据库硬依赖（P1）

**问题**: `app.py:44-63` 保留了 `allow_memory_fallback` 分支，引入双路径复杂度。
[Decision 0020] 已确认 DB 为硬依赖。

### 改动

**1. `src/gateway/app.py` — 移除 fallback 分支**

```python
# before
db_session_factory = None
engine = None
try:
    engine = await create_db_engine(settings.database)
    await ensure_schema(engine, settings.database.schema_)
    db_session_factory = make_session_factory(engine)
    logger.info("db_connected")
except Exception:
    if not settings.database.allow_memory_fallback:
        logger.exception("db_connection_failed", ...)
        raise
    logger.warning("db_unavailable", msg="Running in memory-only mode")

# after
# [Decision 0020] DB is mandatory; startup fails if DB/schema unavailable.
engine = await create_db_engine(settings.database)
await ensure_schema(engine, settings.database.schema_)
db_session_factory = make_session_factory(engine)
logger.info("db_connected")
```

**2. `src/config/settings.py` — 移除 `allow_memory_fallback` 字段**

**3. `.env_template`** — 移除 `DATABASE_ALLOW_MEMORY_FALLBACK` 条目（如存在）。

**4. `src/session/manager.py` — 收紧 `db_session_factory` 类型**

```python
# before
def __init__(self, db_session_factory: async_sessionmaker | None = None) -> None:
    self._db: async_sessionmaker | None = db_session_factory

# after
def __init__(self, db_session_factory: async_sessionmaker) -> None:
    self._db: async_sessionmaker = db_session_factory
```

**5. `src/session/manager.py` — 移除 `_db is None` 守卫**

`_persist_message`、`load_session_from_db` 中的 None 检查不可达，移除。

---

## R5: 前端 history 加载策略（P2）

**问题**: `chat.ts:251-253` 按 `role:content` 去重，会吞掉同内容多轮消息。

### 方案：reconnect 全量替换 + 重连守卫 + 失败恢复 + 输入保护

**loadHistory 时全量替换本地消息，不做增量 merge。**

**重连守卫**: `onConnected` → `loadHistory` → response 返回前，`sendMessage`
必须阻断（否则乐观追加被全量替换覆盖）。

**失败恢复**: `pendingHistoryId` 必须在 success / error / disconnect 三路清理，
否则守卫永久锁死。

**输入保护**: `sendMessage` 返回 boolean，UI 仅在 true 时清空输入。

### 改动

**1. `src/frontend/src/stores/chat.ts` — `isHistoryLoading` + `sendMessage` 返回 boolean**

```typescript
interface ChatState {
  messages: ChatMessage[]
  connectionStatus: ConnectionStatus
  isStreaming: boolean
  isHistoryLoading: boolean  // 新增
  // ...
  sendMessage: (content: string) => boolean  // 返回值改为 boolean
}
```

```typescript
isHistoryLoading: false,

sendMessage: (content: string): boolean => {
  if (!wsClient?.isConnected) return false
  if (pendingHistoryId !== null) return false
  // ... 发送逻辑
  return true
},

loadHistory: () => {
  if (!wsClient?.isConnected) return
  const requestId = crypto.randomUUID()
  pendingHistoryId = requestId
  set({ isHistoryLoading: true }, false, "historyLoading")
  wsClient.send({
    type: "request",
    id: requestId,
    method: "chat.history",
    params: { session_id: "main" },
  })
},
```

**2. `src/frontend/src/stores/chat.ts` — `pendingHistoryId` 三路清理**

```typescript
function clearHistoryGuard() {
  pendingHistoryId = null
  set({ isHistoryLoading: false }, false, "historyLoaded")
}
```

**路径 A — success response**:

```typescript
case "response": {
  if (message.id !== pendingHistoryId) break
  clearHistoryGuard()

  const historyMessages: ChatMessage[] = message.data.messages.map(
    (hm: HistoryMessage) => ({
      id: crypto.randomUUID(),
      role: hm.role,
      content: hm.content,
      timestamp: hm.timestamp
        ? new Date(hm.timestamp).getTime()
        : Date.now(),
      status: "complete" as const,
    })
  )

  set(
    { messages: historyMessages, isStreaming: false },
    false,
    "loadHistory"
  )
  break
}
```

**路径 B — error response**:

```typescript
case "error": {
  if (message.id === pendingHistoryId) {
    clearHistoryGuard()
  }
  // ... 现有 error 处理逻辑
}
```

**路径 C — 连接状态变更**:

```typescript
_setConnectionStatus: (status: ConnectionStatus) => {
  if (status === "reconnecting" || status === "disconnected") {
    if (pendingHistoryId !== null) {
      clearHistoryGuard()
    }
  }
  // ... 现有逻辑
}
```

**3. `src/frontend/src/components/chat/MessageInput.tsx` — 绑定 `isHistoryLoading` + 条件清空**

```typescript
const isHistoryLoading = useChatStore((state) => state.isHistoryLoading)
const isDisabled = isStreaming || connectionStatus !== "connected" || isHistoryLoading

const handleSend = useCallback(() => {
  const trimmed = input.trim()
  if (!trimmed || isDisabled) return
  const sent = sendMessage(trimmed)
  if (sent) {
    setInput("")
    const el = textareaRef.current
    if (el) el.style.height = "auto"
  }
}, [input, isDisabled, sendMessage])

// placeholder 分三态
placeholder={
  connectionStatus !== "connected"
    ? "Connecting..."
    : isHistoryLoading
      ? "Loading history..."
      : "Type a message..."
}
```

### 后续演进路径（不在本次范围）

- 稳定 message_id + 增量 merge（M1.4+）
- SESSION_BUSY 前端 toast 提示与自动重试（M1.4+）

---

## R6: 补充测试（P3）

### 6a: session persistence 测试

新建 `tests/test_session_persistence.py`。

| 用例 | 场景 | 期望 |
|------|------|------|
| 并发 SessionRecord 创建 | 两个 `_persist_message` 同时插入同一 session_id 首条消息 | upsert 幂等，不抛异常 |
| 跨 worker seq 唯一性 | 模拟两个 `_persist_message` 并发执行（同一 session_id） | 两条消息获得不同 seq |
| seq 冲突探测 | mock 绕过 counter 制造 `(session_id, seq)` 冲突 | IntegrityError 传播到调用方 |
| persist 失败后内存干净 | mock DB 抛连接异常 | `append_message` 抛出，`session.messages` 长度不变（无幽灵消息） |
| persist 失败传播 | mock DB 抛连接异常 | 调用方收到异常（非 silent drop） |

### 6b: session 串行化测试

新建 `tests/test_session_serialization.py`。
TTL 参数测试中设为 2s，避免等待。

| 用例 | 场景 | 期望 |
|------|------|------|
| 同 session 并发 claim | 两个 `try_claim_session` 并发调用同一 session_id | 一个返回 lock_token，另一个返回 None |
| SESSION_BUSY RPC 响应 | claim 返回 None 时 gateway 行为 | 返回 `{"type":"error","error":{"code":"SESSION_BUSY",...}}` |
| 正常释放（token 匹配） | claim → release（正确 token）→ 再次 claim | 第二次 claim 成功 |
| 释放 token 不匹配 | Worker A claim → Worker B 超时接管 → Worker A release | A 的 release 是 no-op（token 不匹配），B 的锁不受影响 |
| 超时自动释放 | claim 后不 release，TTL（2s）过期后再 claim | 第二次 claim 成功 |
| TTL 可配置 | 传入不同 ttl_seconds 值 | claim/超时行为与参数一致 |
| 跨 worker 上下文连续性 | Worker A claim → append 多条消息 → release → Worker B claim → `load_session_from_db(force=True)` → `get_history` | 返回包含 A 写入的全部历史消息 |
| force reload 失败中断 | claim 成功 → mock DB 异常 → `load_session_from_db(force=True)` | 异常传播（不返回 False），请求中断 |

### 6c: chat.history contract 测试

在 `tests/test_session_history_filter.py` 补充：

| 用例 | 场景 | 期望 |
|------|------|------|
| 连续相同内容消息不被吞 | 用户连续发两条相同 content | history 返回两条 |
| 仅 user+assistant | 包含 system/tool 的 session | 结果中无 system/tool |
| 空 session | 不存在的 session_id | 返回空列表 |

### 6e: 配置校验测试

在 `tests/test_config.py` 补充：

| 用例 | 场景 | 期望 |
|------|------|------|
| TTL=0 启动失败 | `GATEWAY_SESSION_CLAIM_TTL_SECONDS=0` | `get_settings()` 抛 `ValidationError` |
| TTL 负值启动失败 | `GATEWAY_SESSION_CLAIM_TTL_SECONDS=-1` | `get_settings()` 抛 `ValidationError` |
| TTL 超上限启动失败 | `GATEWAY_SESSION_CLAIM_TTL_SECONDS=3601` | `get_settings()` 抛 `ValidationError` |
| TTL 合法值正常启动 | `GATEWAY_SESSION_CLAIM_TTL_SECONDS=60` | `get_settings()` 成功，值为 60 |

### 6f: 前端守卫恢复测试（手动验收）

vitest 基础设施待 M1.4 搭建，以下用例作为手动验收项：

| 用例 | 场景 | 期望 |
|------|------|------|
| history error 后守卫解除 | chat.history 返回 error | `isHistoryLoading` → false，输入框恢复 |
| 断连后守卫解除 | loadHistory 后断连 | `isHistoryLoading` → false |
| 禁发窗口 UI 反馈 | history 加载期间 | 输入框 disabled，placeholder "Loading history..." |
| 发送成功才清空 | `sendMessage` 返回 false | 输入框保留内容 |
| SESSION_BUSY 提示 | 后端返回 SESSION_BUSY error | toast 提示，输入框恢复可用 |

---

## 清理：移除死代码

**`src/session/manager.py`** — 删除 `get_history_from_db` 方法。

理由：
- `app.py` 已改为调用 `get_history_for_display`，`get_history_from_db` 无调用方。
- 该方法返回 OpenAI 全量格式，与 [Decision 0019] 矛盾，保留会诱导误用。

---

## 文件变更汇总

| 文件 | 改动项 |
|------|--------|
| `src/session/models.py` | R1: SessionRecord 加 `next_seq` + `lock_token` + `processing_since`；MessageRecord 加 UNIQUE 约束 |
| `src/session/manager.py` | R1: `append_message` async + 先 DB 后内存 + `_persist_message` DB 级 seq + `try_claim_session`/`release_session`（lock_token 租约）+ `load_session_from_db` force 参数；R2: 收紧 `_db` 类型 + 移除 None 守卫；清理: 删 `get_history_from_db` |
| `src/agent/agent.py` | R1: 4 处 `append_message` 调用加 `await` |
| `src/gateway/app.py` | R1: `_handle_chat_send` 包装 claim + force reload + release（lock_token）+ SESSION_BUSY；R2: 移除 fallback 分支 |
| `src/config/settings.py` | R1: GatewaySettings 新增 `session_claim_ttl_seconds`；R2: 移除 `allow_memory_fallback` |
| `.env_template` | R2: 移除 `DATABASE_ALLOW_MEMORY_FALLBACK`；新增 `GATEWAY_SESSION_CLAIM_TTL_SECONDS`（可选） |
| `src/frontend/src/stores/chat.ts` | R5: loadHistory 全量替换 + `isHistoryLoading` + `sendMessage` boolean + 三路清理 |
| `src/frontend/src/components/chat/MessageInput.tsx` | R5: 绑定 `isHistoryLoading` + 条件清空 + placeholder 三态 |
| `tests/test_session_persistence.py` | R6a: 新建，5 组持久化测试 |
| `tests/test_session_serialization.py` | R6b: 新建，8 组串行化测试（含 lock_token 匹配/不匹配、TTL 可配置、跨 worker 上下文连续性、force reload 失败中断） |
| `tests/test_session_history_filter.py` | R6c: 补 3 组 history contract 测试 |
| `tests/test_config.py` | R6e: 补 4 组 TTL 配置校验测试 |

共 **12 个文件**：8 个修改，3 个新建，1 个可能修改（`.env_template`）。

## 提交顺序

```
1. fix(session): DB-level seq allocation + synchronous persist + memory consistency [Decision 0021]
   - SessionRecord 加 next_seq + lock_token + processing_since 列
   - _persist_message: atomic seq via INSERT ... ON CONFLICT DO UPDATE ... RETURNING
   - append_message: sync → async, persist first then memory (no ghost messages)
   - load_session_from_db: 增加 force 参数（跨 worker 会话预加载）
   - (session_id, seq) UNIQUE 约束（安全网）
   - agent.py: 4 处调用加 await
   - DB migration: 加列 + 加约束 + 回填 next_seq

2. feat(session): session-level lease lock with lock_token and configurable TTL [Decision 0021/0022]
   - try_claim_session: 返回 lock_token (UUID)
   - release_session: WHERE lock_token 匹配释放（防误释放）
   - gateway _handle_chat_send: claim → force reload → process → release
   - GATEWAY_SESSION_CLAIM_TTL_SECONDS 配置（默认 300s, gt=0, le=3600）
   - SESSION_BUSY RPC error code

3. refactor(gateway): remove memory fallback, enforce DB hard dependency [Decision 0020]
   - 删除 allow_memory_fallback + fallback 分支
   - SessionManager._db 类型收紧

4. refactor(session): remove unused get_history_from_db method [Decision 0019]

5. fix(frontend): full history reload + reconnect guard with failure recovery [Decision 0021]
   - loadHistory 全量替换
   - isHistoryLoading + sendMessage boolean + 三路清理
   - MessageInput 绑定 + 条件清空 + placeholder 三态

6. test(session): persistence, serialization, history contract, and config validation tests
   - 5 组持久化测试 (含内存一致性)
   - 8 组串行化测试 (含 lock_token 匹配、TTL 可配置、跨 worker 上下文连续性、force reload 失败中断)
   - 3 组 history contract 测试
   - 4 组配置校验测试 (TTL fail-fast)
```

## 验证

```bash
# 1. Migration 烟测
uv run alembic upgrade head
psql -d neomagi -c "\d neomagi.sessions"  # 验证 next_seq + lock_token + processing_since
psql -d neomagi -c "SELECT conname FROM pg_constraint WHERE conname = 'uq_messages_session_seq';"
uv run alembic downgrade -1 && uv run alembic upgrade head

# 2. 后端测试
uv run pytest tests/test_session_persistence.py tests/test_session_serialization.py tests/test_session_history_filter.py -v
uv run pytest tests/ -v

# 3. Lint
uv run ruff check src/session/ src/agent/agent.py src/gateway/app.py src/config/settings.py

# 4. 前端构建验证
cd src/frontend && pnpm build

# 5. 手动验收（见 R6f 用例表）
```

## 验收标准

1. **[Decision 0021] 同一 session_id 跨 worker 请求串行化**：并发 claim 只有一个成功（返回 lock_token），另一个返回 SESSION_BUSY
2. **[Decision 0021] lock_token 不匹配时 release 为 no-op**：超时接管后原持有者的 release 不影响新持有者
3. **[Decision 0021] 多 worker 并发写入同一 session_id 时，DB 中 seq 唯一且单调递增**
4. **[Decision 0021] 持久化失败向调用方显式传播**（`append_message` 抛异常 → RPC error）
5. **[Decision 0021] 持久化失败后内存状态不变**（无幽灵消息）
6. **[Decision 0021] UNIQUE 约束存在**（安全网；IntegrityError 传播到调用方）
7. **重连期间 `sendMessage` 被守卫阻断，输入框 disabled + placeholder 提示**
8. **history 请求失败或断连时，守卫自动解除**
9. **`sendMessage` 返回 false 时，输入框内容不被清空**
10. **history 全量替换后，不出现消息重复或丢失**
11. **TTL 可配置（`GATEWAY_SESSION_CLAIM_TTL_SECONDS`），测试使用短 TTL 验证超时行为**
12. **[Decision 0021] 跨 worker 顺序切换后上下文连续**：Worker A 写入 → Worker B 接手 → prompt 包含 A 的全部历史
13. **[Decision 0021] force reload 失败即中断请求**：`load_session_from_db(force=True)` DB 异常 → INTERNAL_ERROR 返回客户端，不继续用空/旧缓存执行
14. **[Decision 0022] TTL 配置有 fail-fast 校验**（`gt=0, le=3600`），非法值启动即报 `ValidationError`
15. **[Decision 0022] release 失败不向客户端二次报错**，只记日志，依赖 TTL 回收
16. **与 Decision 0019/0020/0021/0022 一致，关键路径有决议注释锚点**

## 不在本次范围

| 项目 | 去向 | 说明 |
|------|------|------|
| 稳定 message_id 贯穿前后端 | M1.4+ | 增量同步需 client_message_id + server_message_id |
| 前端 vitest 基础设施 | M1.4 | 守卫恢复测试当前为手动验收 |
| history 请求超时兜底 | M1.4 | error + disconnect 两路清理覆盖正常故障路径 |
| SESSION_BUSY 前端自动重试 | M1.4+ | 当前仅 toast 提示，用户手动重发 |
| session sticky 路由（nginx/LB） | 后续评估 | 当前 try-lock 保证正确性；sticky 可减少 BUSY 频率 |
| 锁 fencing / heartbeat 续租 | M1.4 | 当前 lock_token 防误释放 + 300s TTL 覆盖绝大多数场景；超时后并发处理为 quality degradation 非 data corruption；M1.4 在 `_persist_message` 加 token 校验（fencing）或后台续租（heartbeat）达到更强串行化语义 |
