# M1.4 审计修复收尾 + 测试基础设施

## Context

M1.4 是 P1 核心代理闭环的最后一个里程碑，收尾 M1.2/M1.3 审计延期项，补齐测试基础设施。

**来源**:
- M1.2 审计延期：F4（token 级流式恢复）+ F6b（集成测试）
- M1.3 评审延期：PG 集成测试基础设施 + CI + vitest + history 超时 + 锁 fencing
- Roadmap: `design_docs/roadmap_milestones_v2.md` M1.4 节

**当前代码状态**:
- `agent.py` 使用 `chat_completion`（非流式）处理 tool loop 和 final answer，TextChunk 一次性 yield 整个回复
- `model_client.py` 已有 `chat_stream` 方法支持 streaming，但不处理 tool_calls delta
- 前端 `chat.ts` 已支持 `stream_chunk` 消息增量渲染
- 无 `tests/conftest.py`，现有测试全部基于 mock
- 无 `.github/` 目录，无 CI
- 前端无 vitest 配置，无测试依赖
- `_persist_message` 不验证 lock_token（已知限制，M1.3 plan 明确推迟到此）
- history 请求无超时兜底
- DB 配置使用 `DATABASE_HOST/PORT/USER/PASSWORD/NAME` 分字段模式（`settings.py` env_prefix + `alembic/env.py` os.getenv）

## 总体策略

分 4 个 Phase 实施，每个 Phase 内部可独立验证。依赖关系：

```
Phase 1 (测试基础设施)  ──┐
                          ├──→ Phase 4 (集成测试)
Phase 2 (可靠性增强)     ──┤
                          │
Phase 3 (流式恢复)       ──┘
```

- Phase 1/2/3 之间无依赖，可并行或任意顺序
- Phase 4 依赖 Phase 1（PG fixture）和 Phase 3（流式改动后的集成测试）

---

## Phase 1: 测试基础设施 (T1 + T2 + T3)

### T1: PG 集成测试基础设施

**目标**: 创建 `tests/conftest.py`，提供容器化 PG fixture，使真实 DB 测试可执行。

**方案**: 使用 `testcontainers-python` 启动临时 PostgreSQL 容器。

**改动**:

**1. `pyproject.toml` — dev 依赖新增**
```
testcontainers[postgres]>=4.0.0
httpx>=0.27.0        # FastAPI TestClient 的 async 支持（F6b 需要）
```

**2. `tests/conftest.py` — 新建**

DB 来源优先级：
1. 环境变量 `TEST_DATABASE_HOST` 等存在 → 直连外部 PG（CI 场景）
2. 否则 → testcontainers 自动启动临时 PG 容器（本地开发场景）

安全硬保护：
```python
def _validate_test_db_name(name: str) -> None:
    """Safety: refuse to truncate a database whose name doesn't contain '_test'."""
    if "_test" not in name.lower():
        raise RuntimeError(
            f"Refusing to run tests against database '{name}': "
            "name must contain '_test' to prevent accidental data loss. "
            "Set TEST_DATABASE_NAME to a test-specific database."
        )
```
- 每次 truncate 前调用此校验
- testcontainers 显式指定 `dbname="neomagi_test"` → 通过
- CI 设置 `TEST_DATABASE_NAME=neomagi_test` → 通过
- 误设为 `neomagi`（生产库名）→ 不含 `_test` → 拒绝，测试中断

testcontainers 容器创建：
```python
# 显式指定 dbname，不依赖 testcontainers 默认值
postgres_container = PostgresContainer("postgres:16", dbname="neomagi_test")
```

提供以下 fixture:

| fixture | scope | 作用 |
|---------|-------|------|
| `pg_url` | session | 从 `TEST_DATABASE_*` 环境变量构造 URL，或启动 testcontainers 容器 |
| `db_engine` | session | 基于 `pg_url` 创建 async engine + `CREATE SCHEMA` + 建表 |
| `db_session_factory` | session | 基于 `db_engine` 创建 `async_sessionmaker` |
| `session_manager` | function | 每个测试函数一个 `SessionManager` 实例，测试后 truncate 所有表（保留结构，清数据） |

关键设计:
- session scope 的容器和 engine 避免每个测试重复启动/停止容器
- function scope 的 truncate + 新 SessionManager 实例保证测试隔离
- 使用 `pytest.mark.integration` marker，可通过 `-m integration` 筛选
- 非 integration 测试保持现有行为不受影响
- **不复用 `DATABASE_*` 环境变量**，只读 `TEST_DATABASE_*`，杜绝误连开发/生产库

**3. 集成测试用例（至少 3 条核心路径）**

新建 `tests/integration/test_session_db.py`:

| 用例 | 场景 | 期望 |
|------|------|------|
| claim + release 基本流程 | claim → release → 再 claim | 全部成功 |
| seq 原子分配 | 并发 2 个 `append_message` 写同一 session | 获得不同 seq，无 IntegrityError |
| force reload 数据一致 | Manager A 写 3 条消息 → Manager B `load_session_from_db(force=True)` | B 看到 A 的全部 3 条消息 |
| claim 互斥 | 并发 2 个 `try_claim_session` | 一个成功一个返回 None |
| TTL 过期回收 | claim 后 TTL(2s) 过期 → 再 claim | 第二次成功 |
| fencing 拦截过期 worker | A claim → B 超时接管(TTL=2s) → A 用旧 token 调 append_message | SessionFencingError |

### T2: CI 落地

**目标**: GitHub Actions workflow，执行 migration + 全量测试 + lint。

**改动**:

**1. `.github/workflows/ci.yml` — 新建**

```yaml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: neomagi_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5

    env:
      # Alembic migration 读取 DATABASE_* (运行时配置)
      DATABASE_HOST: localhost
      DATABASE_PORT: 5432
      DATABASE_USER: test
      DATABASE_PASSWORD: test
      DATABASE_NAME: neomagi_test
      DATABASE_SCHEMA: neomagi
      # conftest.py 读取 TEST_DATABASE_* (测试隔离配置)
      TEST_DATABASE_HOST: localhost
      TEST_DATABASE_PORT: 5432
      TEST_DATABASE_USER: test
      TEST_DATABASE_PASSWORD: test
      TEST_DATABASE_NAME: neomagi_test
      # Settings 必需
      OPENAI_API_KEY: sk-test-dummy

    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --all-extras
      - run: uv run alembic upgrade head
      - run: uv run ruff check src/ tests/
      - run: uv run pytest tests/ -v --tb=short

  frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
        with:
          version: latest
      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: pnpm
          cache-dependency-path: src/frontend/pnpm-lock.yaml
      - run: cd src/frontend && pnpm install --frozen-lockfile
      - run: cd src/frontend && pnpm build
      - run: cd src/frontend && pnpm test -- --run
```

注意:
- CI 中的 PG 使用 GitHub Actions 原生 `services`（不是 testcontainers），避免 Docker-in-Docker
- `DATABASE_*` 供 alembic migration 使用，`TEST_DATABASE_*` 供 conftest.py 使用
- 两组值一致（指向同一个 `neomagi_test` 库），但语义分离：运行时配置 vs 测试配置
- 本地开发只需安装 podman/docker，testcontainers 自动管理，零环境变量配置

**2. `justfile` — 新增 test 命令**

```just
# Run all tests
test:
    uv run pytest tests/ -v

# Run integration tests only (requires PostgreSQL or testcontainers)
test-integration:
    uv run pytest tests/ -v -m integration

# Run unit tests only (no DB required)
test-unit:
    uv run pytest tests/ -v -m "not integration"

# Run frontend tests
test-frontend:
    cd {{frontend_dir}} && pnpm test -- --run
```

### T3: 前端 vitest 基础设施

**目标**: 前端添加 vitest + testing-library，将 M1.3 R6f 手动验收项自动化。

**改动**:

**1. 前端 dev 依赖新增**
```
vitest
@testing-library/react
@testing-library/jest-dom
jsdom
```

**2. `src/frontend/vitest.config.ts` — 新建**

```typescript
import { defineConfig } from "vitest/config"
import react from "@vitejs/plugin-react"
import path from "path"

export default defineConfig({
  plugins: [react()],
  test: {
    environment: "jsdom",
    globals: true,
    setupFiles: ["./src/test/setup.ts"],
  },
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "./src"),
    },
  },
})
```

**3. `src/frontend/src/test/setup.ts` — 新建**

```typescript
import "@testing-library/jest-dom/vitest"
```

**4. `src/frontend/package.json` — 新增 test script**
```json
"test": "vitest"
```

**5. `src/frontend/src/stores/__tests__/chat.test.ts` — 新建**

覆盖 M1.3 R6f 手动验收项:

| 用例 | 场景 | 期望 |
|------|------|------|
| history error 后守卫解除 | `_handleServerMessage` 收到 error（id 匹配 pendingHistoryId） | `isHistoryLoading` → false |
| 断连后守卫解除 | `_setConnectionStatus("disconnected")` | `isHistoryLoading` → false |
| history 加载期间发送被阻断 | `isHistoryLoading=true` 时调用 `sendMessage` | 返回 false |
| 发送成功返回 true | 正常连接状态下 `sendMessage` | 返回 true |
| 全量替换无重复 | 先有本地消息 → 收到 history response | messages 被完全替换，无重复 |

测试策略: mock `WebSocketClient`，直接调用 store 内部方法验证状态转换。

---

## Phase 2: 可靠性增强 (R1 + R2)

### R1: history 请求超时兜底

**问题**: 前端 `loadHistory` 发出后，若后端无响应（网络丢包、后端崩溃），`pendingHistoryId` 永远不清理，守卫永久锁死输入。

**方案**: 前端 `loadHistory` 发出后启动 timeout（默认 10s），超时后清理守卫 + toast 提示。

**改动**:

**1. `src/frontend/src/stores/chat.ts` — loadHistory 添加超时机制**

```typescript
loadHistory: () => {
  if (!wsClient?.isConnected) return
  const requestId = crypto.randomUUID()
  pendingHistoryId = requestId
  set({ isHistoryLoading: true }, false, "historyLoading")
  wsClient.send({
    type: "request",
    id: requestId,
    method: "chat.history",
    params: { session_id: "main" },
  })

  // Timeout guard: prevent indefinite pending state
  setTimeout(() => {
    if (pendingHistoryId === requestId) {
      clearHistoryGuard()
      toast.warning("History loading timed out. You can continue chatting.")
    }
  }, 10_000)
},
```

关键: `setTimeout` 回调检查 `pendingHistoryId === requestId` 确保只清理自己的请求，不误清后续请求。

### R2: 锁 fencing（`_persist_message` 原子 token 校验）

**问题**: M1.3 已知限制 — Worker A 超时后 B 拿到锁，A 不知锁被偷继续写入，产生上下文错序。

**方案**: `_persist_message` 将 lock_token 校验嵌入已有的 `ON CONFLICT DO UPDATE ... WHERE` 子句中，单条 SQL 保证原子性，零竞态窗口。

这需要 agent loop 和 gateway 层传递 `lock_token` 到 `_persist_message`。

**改动**:

**1. `src/session/manager.py` — `append_message` / `_persist_message` 增加 `lock_token` 参数**

```python
async def append_message(
    self,
    session_id: str,
    role: str,
    content: str,
    *,
    tool_calls: list[dict[str, Any]] | None = None,
    tool_call_id: str | None = None,
    lock_token: str | None = None,
) -> Message:
    # ...existing code...
    await self._persist_message(session_id, msg, lock_token=lock_token)
    # ...
```

```python
async def _persist_message(
    self, session_id: str, msg: Message, *, lock_token: str | None = None
) -> None:
    """Persist message with atomic fencing.

    Fencing is embedded in the ON CONFLICT WHERE clause — single statement,
    no race window between lock_token check and seq allocation.

    PostgreSQL guarantees: the INSERT ... ON CONFLICT DO UPDATE acquires a
    row-level lock on the conflicting row. Concurrent claims and persists
    on the same session_id are serialized at the row lock level.
    """
    from sqlalchemy.dialects.postgresql import insert as pg_insert

    async with self._db() as db_session:
        stmt = pg_insert(SessionRecord).values(id=session_id, next_seq=1)
        update_set = {"next_seq": SessionRecord.next_seq + 1}

        if lock_token is not None:
            # Fencing: only allow update if lock_token matches or is NULL.
            # If WHERE is false (token mismatch), no update → RETURNING empty → fencing failed.
            stmt = stmt.on_conflict_do_update(
                index_elements=["id"],
                set_=update_set,
                where=or_(
                    SessionRecord.lock_token == lock_token,
                    SessionRecord.lock_token.is_(None),
                ),
            )
        else:
            stmt = stmt.on_conflict_do_update(
                index_elements=["id"],
                set_=update_set,
            )

        stmt = stmt.returning(SessionRecord.next_seq - 1)
        result = await db_session.execute(stmt)
        seq = result.scalar_one_or_none()

        if seq is None:
            # ON CONFLICT WHERE was false → lock_token mismatch
            raise SessionFencingError(
                f"Lock token mismatch for session {session_id}: "
                "another worker has taken over"
            )

        db_session.add(MessageRecord(
            session_id=session_id, seq=seq,
            role=msg.role, content=msg.content,
            tool_calls=msg.tool_calls, tool_call_id=msg.tool_call_id,
        ))
        await db_session.commit()
```

**原子性保证**: `INSERT ... ON CONFLICT DO UPDATE ... WHERE lock_token = :token ... RETURNING` 是单条 SQL 语句。PostgreSQL 在执行 ON CONFLICT 分支时持有行锁，`try_claim_session`（更新 lock_token）和 `_persist_message`（校验 lock_token + 分配 seq）不可能在同一行上并发执行——后到者阻塞等待行锁释放后读到已提交的最新 lock_token。

**`seq is None` 的唯一含义**: session 已存在（有 conflict）但 WHERE 条件不满足（token 不匹配且非 NULL）。新 session 场景下 INSERT 直接成功（无 conflict），RETURNING 返回 0，不可能为 None。

**2. `src/infra/errors.py` — 新增 `SessionFencingError`**

```python
class SessionFencingError(GatewayError):
    """Raised when a stale worker tries to write after lock takeover."""
    def __init__(self, message: str = "Session lock fencing check failed") -> None:
        super().__init__(message, code="SESSION_FENCED")
```

**3. `src/agent/agent.py` — `handle_message` 接受 `lock_token` 参数并传递**

```python
async def handle_message(
    self, session_id: str, content: str, *, lock_token: str | None = None
) -> AsyncIterator[AgentEvent]:
    # 所有 append_message 调用加上 lock_token=lock_token
    await self._session_manager.append_message(
        session_id, "user", content, lock_token=lock_token
    )
    # ... tool loop 中的所有 append_message 同理 ...
```

**4. `src/gateway/app.py` — `_handle_chat_send` 传递 `lock_token`**

```python
async for event in agent_loop.handle_message(
    session_id=parsed.session_id,
    content=parsed.content,
    lock_token=lock_token,  # 新增
):
```

**5. 异常处理路径**

`SessionFencingError` → `NeoMAGIError` 子类 → `_handle_rpc_message` 的 `except NeoMAGIError` 捕获 → 返回 `SESSION_FENCED` RPC error → finally `release_session`（token 不匹配时 release 为 no-op，符合预期）。

---

## Phase 3: 全程流式 + tool_calls delta 聚合 (F4)

### 问题分析

当前 `agent.py` L84 使用 `chat_completion`（非流式）。整个 LLM 回复等完才 yield 一个 `TextChunk`，前端无法看到逐 token 输出。首字延迟 = 完整 LLM 生成时间。

M1.1 时有逐 token 流式，但 M1.2 引入 tool loop 后为简化实现改为非流式。F4 需要恢复。

### 方案: B-min（全程流式 + 最小 tool_calls delta 聚合）

**核心思路**: 每轮 LLM 调用都用 streaming。流式过程中：
- `delta.content` → 立即 yield `TextChunk`（final answer token 级输出）
- `delta.tool_calls` → 静默聚合 delta 片段（id、name、arguments 拼接）
- 流结束后，如果聚合到了 tool_calls → 执行 tool → 继续 loop
- 如果只有 content → 此轮是 final answer，loop 结束

**改动**:

**1. `src/agent/model_client.py` — 新增 `StreamEvent` 类型和 `chat_stream_with_tools` 方法**

```python
from dataclasses import dataclass

@dataclass
class ContentDelta:
    """A chunk of streamed text content."""
    text: str

@dataclass
class ToolCallsComplete:
    """Accumulated tool calls from a completed stream."""
    tool_calls: list  # list of accumulated tool call dicts

StreamEvent = ContentDelta | ToolCallsComplete
```

```python
async def chat_stream_with_tools(
    self,
    messages: list[dict[str, Any]],
    model: str,
    *,
    tools: list[dict] | None = None,
) -> AsyncIterator[StreamEvent]:
    """Stream LLM response, yielding content deltas and accumulated tool calls.

    Content tokens are yielded immediately as ContentDelta.
    Tool call deltas are accumulated silently; after the stream ends,
    a single ToolCallsComplete is yielded if any tool calls were detected.

    OpenAI streaming tool_calls format:
    - First chunk per tool: {index, id, function: {name, arguments: ""}}
    - Subsequent chunks: {index, function: {arguments: "partial..."}}
    - Arguments are partial JSON strings that must be concatenated.
    """
    stream = await self._retry_call(
        lambda: self._client.chat.completions.create(
            model=model,
            messages=messages,
            tools=tools if tools else NOT_GIVEN,
            stream=True,
        ),
        context="chat_stream_with_tools",
    )

    # Accumulate tool_calls delta fragments, keyed by index
    pending_tool_calls: dict[int, dict[str, str]] = {}

    async for chunk in stream:
        if not chunk.choices:
            continue
        delta = chunk.choices[0].delta

        # Content path: yield immediately
        if delta.content:
            yield ContentDelta(text=delta.content)

        # Tool calls path: accumulate delta fragments
        if delta.tool_calls:
            for tc_delta in delta.tool_calls:
                idx = tc_delta.index
                if idx not in pending_tool_calls:
                    pending_tool_calls[idx] = {"id": "", "name": "", "arguments": ""}
                entry = pending_tool_calls[idx]
                if tc_delta.id:
                    entry["id"] = tc_delta.id
                if tc_delta.function:
                    if tc_delta.function.name:
                        entry["name"] = tc_delta.function.name
                    if tc_delta.function.arguments:
                        entry["arguments"] += tc_delta.function.arguments

    # After stream ends: yield accumulated tool calls if any
    if pending_tool_calls:
        yield ToolCallsComplete(
            tool_calls=[pending_tool_calls[i] for i in sorted(pending_tool_calls)]
        )
```

delta 聚合逻辑约 30 行，处理 OpenAI streaming tool_calls 的标准格式。
Gemini/Ollama 的 OpenAI-compatible 端点遵循相同格式。

**2. `src/agent/agent.py` — 使用 `chat_stream_with_tools` 替换 `chat_completion`**

```python
from src.agent.model_client import ContentDelta, ToolCallsComplete

async def handle_message(
    self, session_id: str, content: str, *, lock_token: str | None = None
) -> AsyncIterator[AgentEvent]:
    await self._session_manager.append_message(
        session_id, "user", content, lock_token=lock_token
    )

    system_prompt = self._prompt_builder.build(session_id)
    tools_schema = None
    if self._tool_registry and self._tool_registry.list_tools():
        tools_schema = self._tool_registry.get_tools_schema()

    for iteration in range(MAX_TOOL_ITERATIONS):
        history = self._session_manager.get_history(session_id)
        messages: list[dict[str, Any]] = [
            {"role": "system", "content": system_prompt},
            *history,
        ]

        # Stream the LLM response — content tokens arrive immediately,
        # tool calls are accumulated and yielded at the end of the stream.
        collected_text = ""
        tool_calls_result: list[dict[str, str]] | None = None

        async for event in self._model_client.chat_stream_with_tools(
            messages, self._model, tools=tools_schema
        ):
            if isinstance(event, ContentDelta):
                yield TextChunk(content=event.text)
                collected_text += event.text
            elif isinstance(event, ToolCallsComplete):
                tool_calls_result = event.tool_calls

        # Branch: tool calls detected
        if tool_calls_result:
            tool_calls_data = [
                {
                    "id": tc["id"],
                    "type": "function",
                    "function": {
                        "name": tc["name"],
                        "arguments": tc["arguments"],
                    },
                }
                for tc in tool_calls_result
            ]
            await self._session_manager.append_message(
                session_id,
                "assistant",
                collected_text,  # may be empty when model only returns tool_calls
                tool_calls=tool_calls_data,
                lock_token=lock_token,
            )

            for tc in tool_calls_result:
                parsed_args, parse_err = _safe_parse_args(tc["arguments"])
                if parse_err:
                    logger.warning(
                        "tool_call_args_parse_failed",
                        tool_name=tc["name"],
                        error=parse_err,
                        raw_args=tc["arguments"][:200],
                    )
                yield ToolCallInfo(
                    tool_name=tc["name"],
                    arguments=parsed_args,
                    call_id=tc["id"],
                )

                result = await self._execute_tool(tc["name"], tc["arguments"])
                await self._session_manager.append_message(
                    session_id, "tool", json.dumps(result),
                    tool_call_id=tc["id"], lock_token=lock_token,
                )

            logger.info(
                "tool_call_iteration",
                iteration=iteration + 1,
                tools_called=len(tool_calls_result),
                session_id=session_id,
            )
            continue

        # Branch: no tool calls — this is the final text response
        await self._session_manager.append_message(
            session_id, "assistant", collected_text, lock_token=lock_token
        )
        logger.info(
            "response_complete", session_id=session_id, chars=len(collected_text)
        )
        return

    # Safety: max iterations
    logger.warning("max_tool_iterations", max=MAX_TOOL_ITERATIONS, session_id=session_id)
    yield TextChunk(
        content="I've reached the maximum number of tool calls. Please try again."
    )
```

**关键特性**:
- **首字零额外延迟**: final answer 的首 token 在 LLM 开始生成时就到达前端
- **tool loop 无浪费**: tool_calls 在同一次 streaming 调用中检测，无需二次调用
- **向后兼容**: ToolCallInfo 和 TextChunk 事件格式不变，前端无需改动
- **content + tool_calls 混合**: 部分模型可能同时返回 content 和 tool_calls，代码正确处理

**行为变化说明（content + tool_calls 混合场景）**:

当前（非流式）：tool 调用轮次中 `response.content` 存入 DB 但不 yield TextChunk，前端看不到中间文本。

B-min（全程流式）：tool 调用轮次中如果模型先输出 content tokens 再输出 tool_calls delta，content tokens 会逐 token yield 为 TextChunk，前端可见。

**接受此行为变化**，理由：
1. 前端已正确处理 TextChunk + ToolCallInfo 交错——同一 requestId 的 assistant message 同时累积 content 和 toolCalls
2. 用户看到"让我查一下..."后看到 tool 调用指示器，体验更连贯
3. DB 存储的 assistant message content 更忠实于模型实际输出
4. 实际触发频率低：OpenAI 模型在调用 tool 时通常 content 为空
5. 如果未来需要隐藏，只需在 agent loop 中 buffer content 并在 tool_calls 出现时丢弃——不在 M1.4 做

Phase 4 集成测试将新增一条 content + tool_calls 混合场景用例锁定此预期行为。

**3. `src/agent/model_client.py` — `ModelClient` ABC 新增抽象方法**

```python
@abstractmethod
def chat_stream_with_tools(
    self,
    messages: list[dict[str, Any]],
    model: str,
    *,
    tools: list[dict] | None = None,
) -> AsyncIterator[StreamEvent]:
    """Stream response with tool call support."""
    ...
```

原有的 `chat_completion` 和 `chat_stream` 保留不删除（其他调用方可能使用）。
`agent.py` 从 `chat_completion` 切换到 `chat_stream_with_tools`。

---

## Phase 4: 集成测试 (F6b)

### F6b: WebSocket + Tool Loop 集成测试

**依赖**: T1 (PG fixture) + Phase 3 完成后

**方案**: 使用 `Starlette.TestClient` 的 WebSocket context manager 进行端到端测试。mock `ModelClient` 控制 LLM 回复序列。

**改动**:

**1. `tests/integration/test_websocket.py` — 新建**

| 用例 | 场景 | 期望 |
|------|------|------|
| 基本 chat.send 流式回复 | 发送一条消息 | 收到 stream_chunk(done=false) + stream_chunk(done=true) |
| chat.history 返回历史 | 先 send → 再 history | response 包含 user + assistant 消息 |
| chat.send tool loop 前端事件序列 | mock LLM 返回 tool_call → tool result → final text | 收到 tool_call + stream_chunk 序列 |
| SESSION_BUSY 返回 | 同 session 并发两个 chat.send | 第二个收到 SESSION_BUSY error |
| unknown method | 发送未知 method | 收到 METHOD_NOT_FOUND error |
| 无效 JSON | 发送非 JSON 字符串 | 收到 PARSE_ERROR |

测试中 mock `ModelClient`，不消耗 API quota。

**2. `tests/integration/test_tool_loop_flow.py` — 新建**

验证 tool loop 完整流程的端到端正确性（通过 mock model 回复序列）:

| 用例 | 场景 | 期望 |
|------|------|------|
| 单轮 tool call | LLM stream 返回 tool_calls delta → tool 执行 → final answer stream | DB 中有 user + assistant(tool_calls) + tool + assistant(text) |
| 多轮 tool call | LLM stream 返回 tool_calls × 2 轮 → final answer stream | DB 按序存储所有消息 |
| content + tool_calls 混合流 | mock LLM stream: content tokens → tool_call deltas | 前端收到 TextChunk 后跟 ToolCallInfo；DB assistant message 同时有 content 和 tool_calls |
| tool 执行失败 | tool.execute 抛异常 | 返回 EXECUTION_ERROR 结果，loop 继续 |
| max iterations | tool_calls 超过 MAX_TOOL_ITERATIONS | 返回 safety 文本 |
| fencing 拦截 | 在 tool loop 中间 mock 锁被抢 | SessionFencingError → RPC error |

---

## 文件变更汇总

| 文件 | 改动项 | Phase |
|------|--------|-------|
| `pyproject.toml` | dev 依赖: testcontainers, httpx | P1 |
| `tests/conftest.py` | PG fixture（TEST_DATABASE_* 优先 / testcontainers fallback）+ 库名安全校验 + integration marker | P1/T1 |
| `tests/integration/__init__.py` | 空文件 | P1/T1 |
| `tests/integration/test_session_db.py` | 6 组 PG 集成测试（含 fencing 拦截） | P1/T1 |
| `.github/workflows/ci.yml` | CI workflow（DATABASE_* + TEST_DATABASE_* 双组环境变量） | P1/T2 |
| `justfile` | test / test-integration / test-unit / test-frontend 命令 | P1/T2 |
| `src/frontend/package.json` | vitest + testing-library 依赖 + test script | P1/T3 |
| `src/frontend/vitest.config.ts` | vitest 配置 | P1/T3 |
| `src/frontend/src/test/setup.ts` | testing-library setup | P1/T3 |
| `src/frontend/src/stores/__tests__/chat.test.ts` | 5 组守卫恢复测试 | P1/T3 |
| `src/frontend/src/stores/chat.ts` | R1: loadHistory 超时兜底 | P2/R1 |
| `src/session/manager.py` | R2: append_message / _persist_message 加 lock_token 原子 fencing | P2/R2 |
| `src/infra/errors.py` | R2: SessionFencingError | P2/R2 |
| `src/agent/model_client.py` | F4: StreamEvent 类型 + chat_stream_with_tools 方法 + ABC 新增抽象方法 | P3/F4 |
| `src/agent/agent.py` | R2: handle_message lock_token 传递; F4: 切换到 chat_stream_with_tools | P2+P3 |
| `src/gateway/app.py` | R2: 传递 lock_token 到 handle_message | P2/R2 |
| `tests/integration/test_websocket.py` | 6 组 WebSocket 集成测试 | P4/F6b |
| `tests/integration/test_tool_loop_flow.py` | 6 组 tool loop 端到端测试（含 content+tool_calls 混合、fencing） | P4/F6b |

**共 18 个文件**: 7 个修改，11 个新建。

## 提交顺序

```
1. chore(test): add testcontainers + PG integration test fixture [T1]
   - pyproject.toml dev 依赖
   - tests/conftest.py: TEST_DATABASE_* / testcontainers(dbname=neomagi_test) 双模式 + _test 库名校验
   - tests/integration/test_session_db.py: 6 组核心路径集成测试（含 fencing 拦截）

2. ci: add GitHub Actions workflow with PostgreSQL service [T2]
   - .github/workflows/ci.yml: DATABASE_* + TEST_DATABASE_* 双组配置
   - justfile: test / test-integration / test-unit / test-frontend

3. chore(frontend): add vitest + testing-library infrastructure [T3]
   - vitest.config.ts + setup.ts + package.json
   - 5 组 chat store 守卫恢复测试

4. fix(frontend): add history request timeout guard [R1]
   - loadHistory 10s setTimeout + requestId 校验 + toast

5. feat(session): add lock fencing to _persist_message [R2]
   - append_message / _persist_message lock_token 原子 fencing (ON CONFLICT WHERE)
   - SessionFencingError (SESSION_FENCED)
   - agent.py handle_message + app.py 传递 lock_token

6. feat(agent): restore full-stream with tool_calls delta aggregation [F4]
   - model_client.py: StreamEvent + chat_stream_with_tools
   - agent.py: 切换到 chat_stream_with_tools, tool loop 全程流式

7. test(integration): WebSocket + tool loop integration tests [F6b]
   - 6 组 WebSocket 协议测试
   - 6 组 tool loop 端到端测试（含 content+tool_calls 混合、fencing）
```

## 验收标准

对照 `roadmap_milestones_v2.md` M1.4 验收标准:

1. **final answer 恢复逐 token 流式输出，首字延迟回到 M1.1 水平** — Phase 3 / F4（全程流式，首 token 零额外延迟）
2. **tool loop + 前端状态流转有端到端测试覆盖** — Phase 4 / F6b
3. **PG 集成测试覆盖 claim/release、seq 原子分配、force reload 三条核心路径** — Phase 1 / T1
4. **CI workflow green: migration + pytest + ruff 在 GitHub Actions 上通过** — Phase 1 / T2
5. **前端守卫恢复测试在 vitest 中自动化执行** — Phase 1 / T3
6. **全量测试通过，ruff clean** — 所有 Phase

额外验收（M1.3 延期项）:
7. **history 请求超时不会永久锁死输入** — Phase 2 / R1
8. **`_persist_message` 有原子 fencing 检查，超时接管后旧 worker 写入被拒绝** — Phase 2 / R2
9. **SessionFencingError 通过 RPC 返回给客户端** — Phase 2 / R2

## 不在本次范围

| 项目 | 去向 | 说明 |
|------|------|------|
| 稳定 message_id 贯穿前后端 | M1.4+ | 增量同步基础 |
| SESSION_BUSY 前端自动重试 | M1.4+ | 当前仅 toast 提示 |
| heartbeat 续租 | 后续评估 | fencing 已覆盖核心场景，heartbeat 可按需加入 |
